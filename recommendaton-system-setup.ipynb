{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "# take environment variables from .env.\n",
    "load_dotenv(override=True) \n",
    "\n",
    "search_service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.getenv(\"AZURE_AI_SEARCH_API_KEY\", \"\")) if len(os.getenv(\"AZURE_AI_SEARCH_API_KEY\", \"\")) > 0 else DefaultAzureCredential()\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"recommendationidx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery,\n",
    ")\n",
    "from azure.search.documents.indexes.models import (\n",
    "    HnswAlgorithmConfiguration,\n",
    "    SearchField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "def create_or_update_index(client, index_name):\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchField(\n",
    "            name=\"content\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"embedding\",\n",
    "            type=\"Collection(Edm.SByte)\",  # OData syntax for 8-bit signed integer\n",
    "            vector_search_dimensions=1024,\n",
    "            vector_search_profile_name=\"my-vector-config\",\n",
    "            # hidden=False, Use hidden=False if you want to return the embeddings in the search results\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    vector_search = VectorSearch(\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"my-vector-config\",\n",
    "                algorithm_configuration_name=\"my-hnsw\",\n",
    "            )\n",
    "        ],\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"my-hnsw\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
    "    client.create_or_update_index(index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure Search Index Client\n",
    "search_index_client = SearchIndexClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    credential=credential,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "# Create or update the search index to include the embedding field\n",
    "create_or_update_index(search_index_client, index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk and load documents into AI search\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = DirectoryLoader('data/', glob=\"*.md\", loader_cls=TextLoader, loader_kwargs={'autodetect_encoding': True})\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20).split_documents(docs)\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract page_content from each Document object\n",
    "document_texts = [doc.page_content for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, input_type=\"search_document\"):\n",
    "    model = \"embed-english-v3.0\"\n",
    "    # Ensure texts is a list\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    response = co.embed(\n",
    "        texts=texts,\n",
    "        model=model,\n",
    "        input_type=input_type,\n",
    "        embedding_types=[\"int8\"],\n",
    "    )\n",
    "    return [embedding for embedding in response.embeddings.int8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Initialize Cohere client\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "# Limit to 80 calls per minute as Free Embed API has a limitation of 100 calls per min\n",
    "batch_size = 80\n",
    "embeddings = []\n",
    "for i in range(0, len(document_texts), batch_size):\n",
    "    batch = document_texts[i:i + batch_size]\n",
    "    embeddings.extend(generate_embeddings(batch))\n",
    "    if i + batch_size < len(document_texts):\n",
    "        time.sleep(60)  # Sleep for 60 seconds to respect the rate limit\n",
    "\n",
    "# Generate embeddings\n",
    "# embeddings = generate_embeddings(document_texts)\n",
    "print (len(embeddings), \"Document embeddings generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(search_client, documents, embeddings):\n",
    "    documents_to_index = [\n",
    "        {\"id\": str(idx), \"content\": doc, \"embedding\": emb}\n",
    "        for idx, (doc, emb) in enumerate(zip(documents, embeddings))\n",
    "    ]\n",
    "    search_client.upload_documents(documents=documents_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SearchClient\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_service_endpoint, \n",
    "    index_name=index_name, \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# Index the documents and their embeddings\n",
    "index_documents(search_client, document_texts, embeddings)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
